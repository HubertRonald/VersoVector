{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "import sys; sys.path.insert(0, '..')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# python\n",
    "import os\n",
    "import ssl\n",
    "import csv\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import session_info\n",
    "\n",
    "from pathlib import Path\n",
    "from inspect import cleandoc\n",
    "\n",
    "# utils\n",
    "from utils import Constants\n",
    "\n",
    "# stat\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import jaccard_score # Métrica común para multilabel\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "# typings\n",
    "from pandas import DataFrame as PandasDF\n",
    "from typing import List, Dict, Union\n",
    "\n",
    "# warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=ConvergenceWarning)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# setup\n",
    "plt.style.use('seaborn-v0_8')\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('max_colwidth', None)\n",
    "# decimals\n",
    "np.set_printoptions(precision=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargar el dataset sklearn\n",
    "if not os.environ.get('CI'):\n",
    "    ssl._create_default_https_context =\\\n",
    "        ssl._create_unverified_context\n",
    "          \n",
    "# rutas absolutas\n",
    "here: Path = Path.cwd().absolute().parent\n",
    "data: Path = here / 'data'\n",
    "poetry_fundation_cleaned: Path = data / 'CleanedPoetryFoundationData.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_load:Dict = dict(\n",
    "    sep=Constants.PIPE_STR,\n",
    "    quotechar='\"',\n",
    "    quoting=csv.QUOTE_NONNUMERIC,\n",
    "    encoding=Constants.ENCODING\n",
    ")\n",
    "\n",
    "if not poetry_fundation_cleaned.is_file():\n",
    "    raise FileNotFoundError(\n",
    "        cleandoc(f'''\n",
    "        El archivo {poetry_fundation_cleaned} no existe.\n",
    "        Por favor, descargue el archivo desde:\n",
    "        https://www.kaggle.com/datasets/abhinavwalia95/poetryfoundationorg\n",
    "        y coloquelo en la carpeta data.\n",
    "        ''')\n",
    "    )\n",
    "    \n",
    "poetry_df: PandasDF = (\n",
    "    pd.read_csv(\n",
    "        str(poetry_fundation_cleaned), \n",
    "        **setup_load\n",
    "    )\n",
    ")\n",
    "\n",
    "poetry_df = poetry_df.loc[~poetry_df.poem.isna(),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clases (etiquetas únicas): [' ' \"'\" ',' '[' ']' 'a' 'b' 'c' 'd' 'e' 'f' 'g' 'h' 'i' 'j' 'k' 'l' 'm'\n",
      " 'n' 'o' 'p' 'q' 'r' 's' 't' 'u' 'v' 'w' 'x' 'y' 'z']\n",
      "\n",
      "Matriz Multilabel (primeras 3 filas):\n",
      " [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 1 1 0 0 1 0]\n",
      " [1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 0 0 0 1 0]\n",
      " [1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "# Instanciar el binarizador\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "# Ajustar y transformar la columna de etiquetas\n",
    "# ¡Asegúrate de pasar una lista de listas!\n",
    "y_mlb = mlb.fit_transform(poetry_df['tags']) \n",
    "\n",
    "# y_mlb ahora es una matriz NumPy donde cada fila es una poesía \n",
    "# y cada columna es una etiqueta binaria (0 o 1).\n",
    "\n",
    "# Para ver las etiquetas (el orden de las columnas):\n",
    "print(\"Clases (etiquetas únicas):\", mlb.classes_)\n",
    "print(\"\\nMatriz Multilabel (primeras 3 filas):\\n\", y_mlb[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Vectorizar el texto\n",
    "vectorizer = TfidfVectorizer(max_features=5000) # Limitar a 5000 palabras más importantes\n",
    "X = vectorizer.fit_transform(poetry_df.poem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Jaccard Score (Micro): 0.8164\n"
     ]
    }
   ],
   "source": [
    "# 1. División de datos (Entrenamiento y Prueba)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_mlb, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 2. Definición del modelo (Clasificador OVR con Regresión Logística)\n",
    "classifier = OneVsRestClassifier(\n",
    "    LogisticRegression(\n",
    "        solver='liblinear',\n",
    "        max_iter=1000,  # Aumenta el número de iteraciones\n",
    "        random_state=42 # Asegura reproducibilidad\n",
    "    )\n",
    ")\n",
    "\n",
    "# 3. Entrenamiento del modelo\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# 4. Predicción\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# 5. Evaluación\n",
    "# jaccard_score es una métrica útil para problemas multilabel\n",
    "jaccard_micro = jaccard_score(y_test, y_pred, average='micro')\n",
    "\n",
    "print(f\"\\nJaccard Score (Micro): {jaccard_micro:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
