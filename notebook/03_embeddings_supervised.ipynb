{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "import sys; sys.path.insert(0, '..')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# python\n",
    "import os\n",
    "import ast\n",
    "import ssl\n",
    "import csv\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "from inspect import cleandoc\n",
    "\n",
    "# utils\n",
    "from utils import Constants\n",
    "from modules.preprocesing import preprocess\n",
    "\n",
    "# stat\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import jaccard_score # Métrica común para multilabel\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "# typings\n",
    "from pandas import DataFrame as PandasDF\n",
    "from typing import Dict\n",
    "\n",
    "# warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=ConvergenceWarning)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# setup\n",
    "plt.style.use('seaborn-v0_8')\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('max_colwidth', None)\n",
    "# decimals\n",
    "np.set_printoptions(precision=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargar el dataset sklearn\n",
    "if not os.environ.get('CI'):\n",
    "    ssl._create_default_https_context =\\\n",
    "        ssl._create_unverified_context\n",
    "          \n",
    "# rutas absolutas\n",
    "here: Path = Path.cwd().absolute().parent\n",
    "data: Path = here / 'data'\n",
    "poetry_fundation_cleaned: Path = data / 'CleanedPoetryFoundationData.csv'\n",
    "cv_poetry: Path = data / 'vallejo_poems_en.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_load:Dict = dict(\n",
    "    sep=Constants.PIPE_STR,\n",
    "    quotechar='\"',\n",
    "    quoting=csv.QUOTE_NONNUMERIC,\n",
    "    encoding=Constants.ENCODING\n",
    ")\n",
    "\n",
    "if not poetry_fundation_cleaned.is_file() or not cv_poetry.is_file():\n",
    "    raise FileNotFoundError(\n",
    "        cleandoc(f'''\n",
    "        El archivo {poetry_fundation_cleaned} no existe.\n",
    "        Por favor, descargue el archivo desde:\n",
    "        https://www.kaggle.com/datasets/abhinavwalia95/poetryfoundationorg\n",
    "        y coloquelo en la carpeta data.\n",
    "        ''')\n",
    "    )\n",
    "    \n",
    "poetry_df: PandasDF = (\n",
    "    pd.read_csv(\n",
    "        str(poetry_fundation_cleaned), \n",
    "        **setup_load\n",
    "    )\n",
    ")\n",
    "\n",
    "cv_df: PandasDF = (\n",
    "        pd.read_csv(\n",
    "        str(cv_poetry), \n",
    "        **setup_load\n",
    "    )\n",
    ")\n",
    "\n",
    "cv_df[['title', 'poem']] = (\n",
    "        cv_df[['title', 'poem']]\n",
    "        .apply(lambda col: col.astype(str).apply(preprocess))\n",
    "    )\n",
    "\n",
    "poetry_df = poetry_df.loc[~poetry_df.poem.isna(),:]\n",
    "poetry_df['tags'] = poetry_df['tags'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clases (etiquetas únicas): ['activities' 'animals' 'anniversary' 'architecture design'\n",
      " 'arts sciences' 'birth' 'birth birthdays' 'birthdays'\n",
      " 'breakups vexed love' 'buddhism' 'christianity' 'christmas'\n",
      " 'cinco de mayo' 'cities urban life' 'class' 'classic love'\n",
      " 'coming of age' 'crime punishment' 'death' 'desire'\n",
      " 'disappointment failure' 'easter' 'eating drinking' 'engagement'\n",
      " 'fairytales legends' 'faith doubt' 'fall' 'family ancestors'\n",
      " 'farewells good luck' 'fathers day' 'first love' 'friends enemies'\n",
      " 'funerals' 'gardening' 'gay' 'gender sexuality' 'get well recovery'\n",
      " 'ghosts the supernatural' 'god the divine' 'graduation'\n",
      " 'gratitude apologies' 'greek roman mythology' 'growing old' 'halloween'\n",
      " 'hanukkah' 'health illness' 'heartache loss' 'heavens'\n",
      " 'heroes patriotism' 'history politics' 'home life' 'horror'\n",
      " 'humor satire' 'independence day' 'indoor activities' 'infancy'\n",
      " 'infatuation crushes' 'islam' 'jobs working' 'judaism' 'kwanzaa'\n",
      " 'labor day' 'landscapes pastorals' 'language linguistics' 'lesbian'\n",
      " 'life choices' 'living' 'love' 'marriage companionship' 'memorial day'\n",
      " 'men women' 'midlife' 'money economics' 'mothers day' 'music'\n",
      " 'mythology folklore' 'nature' 'new year' 'other religions'\n",
      " 'painting sculpture' 'parenthood' 'passover' 'pets' 'philosophy'\n",
      " 'photography film' 'planets' 'poetry poets' 'popular culture' 'queer'\n",
      " 'race ethnicity' 'ramadan' 'reading books' 'realistic complicated'\n",
      " 'relationships' 'religion' 'rivers' 'romantic love' 'rosh hashanah'\n",
      " 'school learning' 'sciences' 'seas' 'separation divorce' 'september th'\n",
      " 'social commentaries' 'sorrow grieving' 'sports outdoor activities'\n",
      " 'spring' 'st patricks day' 'stars' 'streams' 'summer' 'thanksgiving'\n",
      " 'the body' 'the mind' 'the spiritual' 'theater dance' 'time brevity'\n",
      " 'toasts celebrations' 'town country life' 'travels journeys'\n",
      " 'trees flowers' 'unrequited love' 'valentines day' 'war conflict'\n",
      " 'weather' 'weddings' 'winter' 'yom kippur' 'youth']\n",
      "\n",
      "Matriz Multilabel (primeras 2 filas):\n",
      " [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0\n",
      "  0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 1 0 0 0 0\n",
      "  0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# Instanciar el binarizador\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "# Ajustar y transformar la columna de etiquetas\n",
    "# ¡Asegúrate de pasar una lista de listas!\n",
    "y_mlb = mlb.fit_transform(poetry_df['tags']) \n",
    "\n",
    "# y_mlb ahora es una matriz NumPy donde cada fila es una poesía \n",
    "# y cada columna es una etiqueta binaria (0 o 1).\n",
    "\n",
    "# Para ver las etiquetas (el orden de las columnas):\n",
    "print(\"Clases (etiquetas únicas):\", mlb.classes_)\n",
    "print(\"\\nMatriz Multilabel (primeras 2 filas):\\n\", y_mlb[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Vectorizar el texto\n",
    "vectorizer = TfidfVectorizer(max_features=5000) # Limitar a 5000 palabras más importantes\n",
    "X = vectorizer.fit_transform(poetry_df.poem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Jaccard Score (Micro): 0.1389\n"
     ]
    }
   ],
   "source": [
    "# 1. División de datos (Entrenamiento y Prueba)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_mlb, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 2. Definición del modelo (Clasificador OVR con Regresión Logística)\n",
    "classifier = OneVsRestClassifier(\n",
    "    LogisticRegression(\n",
    "        solver='liblinear',\n",
    "        max_iter=1000,  # Aumenta el número de iteraciones\n",
    "        random_state=42 # Asegura reproducibilidad\n",
    "    )\n",
    ")\n",
    "\n",
    "# 3. Entrenamiento del modelo\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# 4. Predicción\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# 5. Evaluación\n",
    "# jaccard_score es una métrica útil para problemas multilabel\n",
    "jaccard_micro = jaccard_score(y_test, y_pred, average='micro')\n",
    "\n",
    "print(f\"\\nJaccard Score (Micro): {jaccard_micro:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xcv = vectorizer.transform(cv_df.poem)\n",
    "ycv_pred = mlb.inverse_transform(\n",
    "    classifier.predict(Xcv)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>black herald</td>\n",
       "      <td>[living]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>black stone white stone</td>\n",
       "      <td>[living]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pari octob poem</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xiii</td>\n",
       "      <td>[living]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     title      tags\n",
       "0             black herald  [living]\n",
       "1  black stone white stone  [living]\n",
       "2          pari octob poem        []\n",
       "3                     xiii  [living]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(dict(\n",
    "    title=cv_df.title.values, \n",
    "    tags=list(map(list,ycv_pred)))\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
