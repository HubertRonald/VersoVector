<p align="left">
    <a href="https://www.python.org/" target="_blank">
        <img src="https://img.shields.io/badge/python-3670A0?style=flat-square&logo=python&logoColor=ffdd54" />
        </a>
    <a href="https://pytorch.org/" target="_blank">
        <img src="https://img.shields.io/badge/PyTorch-red.svg?logo=pytorch?style=flat-square&logoColor=white" />
    </a>
    <a href="https://huggingface.co/" target="_blank">
        <img src="https://img.shields.io/badge/Transformers-yellow.svg?logo=huggingface?style=flat-square&logoColor=white" />
    </a>
    <a href="https://scikit-learn.org/" target="_blank">
        <img src="https://img.shields.io/badge/scikit--learn-orange.svg?logo=scikit-learn?style=flat-square&logoColor=white" />
    </a>
    <a href="https://pandas.pydata.org/" target="_blank">
        <img src="https://img.shields.io/badge/Pandas-DataFrames-green.svg?logo=pandas?style=flat-square&logoColor=white" />
    </a>
    <a href="https://hub.docker.com/r/google/cloud-sdk" target="_blank">
        <img src="https://img.shields.io/badge/docker-%230db7ed.svg?style=flat-square&logo=docker&logoColor=white" />
    </a>
    <a href="https://code.visualstudio.com/download" target="_blank">
        <img src="https://img.shields.io/badge/Visual%20Studio%20Code-007ACC?logo=visualstudiocode&logoColor=fff&flat-square=plastic" />
    </a>
    <img src="https://img.shields.io/github/last-commit/HubertRonald/PoesiaEmbeddingsClusteringClassification?style=flat-square" />
    <img src="https://img.shields.io/github/commit-activity/t/HubertRonald/PoesiaEmbeddingsClusteringClassification?style=flat-square&color=dodgerblue" />
</p>

# Poesia Embeddings Clustering Classification
ExploraciÃ³n de poesÃ­a mediante machine learning: generaciÃ³n de embeddings, clustering y clasificaciÃ³n emocional usando textos de CÃ©sar Vallejo y otros poetas traducidos al inglÃ©s.

> **Nota:** Aunque este proyecto se describe en espaÃ±ol, los datasets y modelos se entrenan con poemas en inglÃ©s, debido a la mayor disponibilidad de recursos NLP en ese idioma.

## ğŸ“– DescripciÃ³n
Este proyecto explora la relaciÃ³n entre el **significado semÃ¡ntico y emocional** de la poesÃ­a a travÃ©s de modelos de *embeddings* modernos.  
Combina dos enfoques de aprendizaje:

- **Aprendizaje no supervisado:** Agrupamiento (clustering) de poemas por estilo o tono.  
- **Aprendizaje supervisado:** ClasificaciÃ³n de poemas por emociÃ³n o tema.

Se busca responder:  
> â€œÂ¿Puede un modelo de lenguaje percibir la emociÃ³n detrÃ¡s de un poema, como lo hace un lector humano?â€

## ğŸ§ªğŸ§  Flujo general del proyecto

CÃ³mo se presentarÃ¡ los modelos a emplear en este repositorio

```mermaid
graph TD
    A[Poemas originales<br>Vallejo + otros] --> B[Preprocesamiento<br>Limpieza y TokenizaciÃ³n]
    B --> C[ExtracciÃ³n de caracterÃ­sticas<br>TF-IDF / BERT embeddings]
    C --> D1[Clustering no supervisado<br>KMeans / GaussianMixture / UMAP]
    C --> D2[ClasificaciÃ³n supervisado<br>LogReg / SVM / BERT]
    D1 --> E1[AnÃ¡lisis de temas y emociones emergentes]
    D2 --> E2[PredicciÃ³n de emociÃ³n o tono poÃ©tico]
```

> **Nota:** Aunque este proyecto se describe en espaÃ±ol, los datasets y modelos se entrenan con poemas en inglÃ©s, debido a la mayor disponibilidad de recursos NLP en ese idioma.

## ğŸ—‚ï¸ Dataset
El dataset combina poemas en dominio pÃºblico y textos etiquetados a partir de fuentes abiertas (HuggingFace / Kaggle).  

Cuando no hay etiquetas manuales, se aplican modelos de AnÃ¡lisis de Sentimientos (*sentiment analysis*) como punto de partida.

## ğŸ§® RepresentaciÃ³n Vectorial de la PoesÃ­a

Para analizar la poesÃ­a desde una perspectiva computacional, los textos deben transformarse en representaciones numÃ©ricas.  
En este proyecto se emplean dos enfoques clÃ¡sicos del procesamiento de lenguaje natural: **CountVectorizer** y **TF-IDF Vectorizer**, antes de generar *embeddings* mÃ¡s complejos.

---

### ğŸ”¹ CountVectorizer

El **CountVectorizer** convierte cada poema en un vector basado en la frecuencia de apariciÃ³n de cada tÃ©rmino.

Sea un corpus con $( D )$ documentos y un vocabulario con $( N )$ tÃ©rminos distintos.  
Para un documento $( d )$ y un tÃ©rmino $( t )$, el valor en la matriz $( X_{d,t} )$ es:

$$
X_{d,t} = \text{count}(t, d)
$$

donde

$$[
\text{count}(t, d) = \text{nÃºmero de veces que el tÃ©rmino } t \text{ aparece en el documento } d
]$$

Cada poema queda representado como un vector:

$$
\mathbf{x}_d = [X_{d,1}, X_{d,2}, ..., X_{d,N}]
$$

---

### ğŸ”¹ TF-IDF Vectorizer

El **TF-IDF (Term Frequencyâ€“Inverse Document Frequency)** pondera la frecuencia de los tÃ©rminos por su rareza en el conjunto de poemas.  
AsÃ­, las palabras comunes reciben menos peso y las mÃ¡s singulares destacan en la representaciÃ³n.

$$
\text{tfidf}(t, d, D) = \text{tf}(t, d) \times \text{idf}(t, D)
$$

donde

$$
\text{tf}(t, d) = \frac{f_{t,d}}{\sum_{t'} f_{t',d}}, \quad
\text{idf}(t, D) = \log\left(\frac{1 + |D|}{1 + |\{d_i \in D : t \in d_i\}|}\right) + 1
$$

Por tanto:

$$
\text{TFIDF}(t, d, D) = \frac{f_{t,d}}{\sum_{t'} f_{t',d}} \times \log\left(\frac{1 + |D|}{1 + |\{d_i \in D : t \in d_i\}|}\right) + 1
$$

---

### âœï¸ Ejemplo prÃ¡ctico â€” *Los Heraldos Negros*

Consideremos la lÃ­nea de CÃ©sar Vallejo:

> â€œHay golpes en la vida, tan fuertes... Â¡Yo no sÃ©!â€

#### ğŸ§© CountVectorizer
Si el vocabulario relevante es  

```python
["golpes", "vida", "fuertes"]
```

entonces:

$$
\mathbf{x}_{\text{count}} = [1, 1, 1]
$$

Cada palabra aparece una vez.

#### ğŸ§© TF-IDF Vectorizer

Supongamos un corpus de tres poemas:

1. â€œHay golpes en la vida, tan fuertes... Â¡Yo no sÃ©!â€
2. â€œGolpes como del odio de Dios.â€
3. â€œSon las caÃ­das hondas de los Cristos del alma.â€

Si el tÃ©rmino *golpes* aparece en 2 de 3 documentos, y *vida* solo en uno:

$$
\text{idf}(\text{golpes}) = \log\left(\frac{1 + 3}{1 + 2}\right) + 1 \approx 1.287
$$

$$
\text{idf}(\text{vida}) = \log\left(\frac{1 + 3}{1 + 1}\right) + 1 \approx 1.693
$$

Dado que cada palabra aparece una vez y el poema tiene 6 tÃ©rminos relevantes:

$$
\text{tf}(t, d) = \frac{1}{6}
$$

Entonces:

$$
\text{tfidf}(\text{golpes}) = \frac{1}{6} \times 1.287 \approx 0.215
$$

$$
\text{tfidf}(\text{vida}) = \frac{1}{6} \times 1.693 \approx 0.282
$$

$$
\text{tfidf}(\text{fuertes}) = \frac{1}{6} \times 1.693 \approx 0.282
$$

Por tanto, el vector TF-IDF serÃ­a:

$$
\mathbf{x}_{\text{tfidf}} = [0.215, 0.282, 0.282]
$$

---

### ğŸ’¡ InterpretaciÃ³n

- **CountVectorizer** solo cuenta ocurrencias: Ãºtil para observar repeticiones lÃ©xicas.
- **TF-IDF** valora la **relevancia semÃ¡ntica** de los tÃ©rminos raros o distintivos.
- En poesÃ­a, donde cada palabra tiene un peso emocional y simbÃ³lico, **TF-IDF** refleja mejor la singularidad expresiva de cada poema.

---



## ğŸ”¹ .gitignore

Fue generado en [gitignore.io](https://www.toptal.com/developers/gitignore/) con los filtros `python`, `macos`, `windows` y consumido mediante su API como archivo crudo desde la terminal:

```bash
curl -L https://www.toptal.com/developers/gitignore/api/python,macos,windows > .gitignore
```

## ğŸª¶ Autores

- **Hubert Ronald** - *Trabajo Inicial* - [HubertRonald](https://github.com/HubertRonald)

- Ve tambiÃ©n la lista de [contribuyentes](https://github.com/HubertRonald/PoesiaEmbeddingsClusteringClassification/contributors) que participaron en este proyecto.


## ğŸ“š Licencia y derechos de autor

El cÃ³digo fuente de este proyecto se distribuye bajo licencia - ver la [LICENCIA](LICENSE) archivo (en inglÃ©s) para mÃ¡s detalle.

Los textos poÃ©ticos utilizados (como los de CÃ©sar Vallejo) provienen de **fuentes de dominio pÃºblico o traducciones disponibles con fines educativos**.

En caso de utilizar materiales con derechos reservados, estos se emplean Ãºnicamente para fines de **investigaciÃ³n, anÃ¡lisis lingÃ¼Ã­stico y demostraciÃ³n acadÃ©mica**, sin fines comerciales.