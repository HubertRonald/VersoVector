<p align="left">
    <a href="https://www.python.org/" target="_blank">
        <img src="https://img.shields.io/badge/python-3670A0?style=flat-square&logo=python&logoColor=ffdd54" />
        </a>
    <a href="https://pytorch.org/" target="_blank">
        <img src="https://img.shields.io/badge/PyTorch-red.svg?logo=pytorch?style=flat-square&logoColor=white" />
    </a>
    <a href="https://huggingface.co/" target="_blank">
        <img src="https://img.shields.io/badge/Transformers-yellow.svg?logo=huggingface?style=flat-square&logoColor=white" />
    </a>
    <a href="https://scikit-learn.org/" target="_blank">
        <img src="https://img.shields.io/badge/scikit--learn-orange.svg?logo=scikit-learn?style=flat-square&logoColor=white" />
    </a>
    <a href="https://pandas.pydata.org/" target="_blank">
        <img src="https://img.shields.io/badge/Pandas-DataFrames-green.svg?logo=pandas?style=flat-square&logoColor=white" />
    </a>
    <a href="https://hub.docker.com/r/google/cloud-sdk" target="_blank">
        <img src="https://img.shields.io/badge/docker-%230db7ed.svg?style=flat-square&logo=docker&logoColor=white" />
    </a>
    <a href="https://code.visualstudio.com/download" target="_blank">
        <img src="https://img.shields.io/badge/Visual%20Studio%20Code-007ACC?logo=visualstudiocode&logoColor=fff&flat-square=plastic" />
    </a>
    <img src="https://img.shields.io/github/last-commit/HubertRonald/VersoVector?style=flat-square" />
    <img src="https://img.shields.io/github/commit-activity/t/HubertRonald/VersoVector?style=flat-square&color=dodgerblue" />
</p>


# Verso Vector
Exploraci√≥n de poes√≠a mediante machine learning: generaci√≥n de embeddings, clustering y clasificaci√≥n emocional usando textos de C√©sar Vallejo y otros poetas traducidos al ingl√©s.

> **Nota:** Aunque este proyecto se describe en espa√±ol, los datasets y modelos se entrenan con poemas en ingl√©s, debido a la mayor disponibilidad de recursos NLP en ese idioma.

## üìñ Descripci√≥n
Este proyecto explora la relaci√≥n entre el **significado sem√°ntico y emocional** de la poes√≠a a trav√©s de modelos de *embeddings* modernos.  
Combina dos enfoques de aprendizaje:

- **Aprendizaje no supervisado:** Agrupamiento (clustering) de poemas por estilo o tono.  
- **Aprendizaje supervisado:** Clasificaci√≥n de poemas por emoci√≥n o tema.

Se busca responder:  
> ‚Äú¬øPuede un modelo de lenguaje percibir la emoci√≥n detr√°s de un poema, como lo hace un lector humano?‚Äù

## üß™ Flujo general del proyecto

C√≥mo se presentar√°n los modelos a emplear en este repositorio


```mermaid
---
title: Flujo de Trabajo
---
%%{init: {
    'look':'handDrawn',
    'theme':'default',
    'flowchart': {
      'layoutDirection': "TD"
    }
  }
}%%
flowchart
    A[Poemas originales<br>Vallejo + otros] --> B[Preprocesamiento<br>Limpieza y Tokenizaci√≥n]

    %% Representaci√≥n expandida
    B --> S2[FeatureUnion]

    subgraph FeatureUnion["Uni√≥n de Caracter√≠sticas"]
        S2 -->|CountVect| S21[CountVectorizer]
        S2 -->|TF-IDF| S22[TfidfVectorizer]

        %% Sub-pipeline DictVect
        S2 --> DV1[TextToDictTransformer]

        subgraph DictVect["DictVect"]
            DV1 --> DV2[DictVectorizer]
        end
    end

    %% uni√≥n de features
    S21 --> S3[ToDense]
    S22 --> S3[ToDense]
    DV2 --> S3[ToDense]

    S3 --> S4[Normalize]

    %% Paso opcional de reducci√≥n dimensional
    S4 --> D[Reducci√≥n Dimensional<br>PCA / t-SNE / UMAP]
    D --> E[Clustering<br>KMeans / GMM / DBSCAN / Agglomerative]

    %% Ramas no supervisadas
    subgraph Clustering["An√°lisis no supervisado"]
        E[Clustering<br>KMeans / GMM / DBSCAN / Agglomerative]
        F[Modelado de T√≥picos<br>LDA]
        G[Similitud<br>Coseno / Correlaci√≥n]
    end

    S4 --> F
    S4 --> G

    E --> H1[Gr√°ficas 2D/3D<br>t-SNE/UMAP + labels]
    F --> H2[An√°lisis de temas]
    G --> H2
    E --> H2[Emociones emergentes]

    %% Rama supervisada
    S4 --> S5[StackingClassifier<br>OneVsRest]

    subgraph Stacking["An√°lisis supervisado"]
        S5 --> S51[MultinomialNB]
        S5 --> S52[ComplementNB]
        S51 --> S6[LogisticRegression<br>final estimator]
        S52 --> S6[LogisticRegression<br>final estimator]
    end

    S6 --> E2[Predicci√≥n de emoci√≥n o<br>tono po√©tico]

    %% Integraci√≥n final
    subgraph Integracion["Integraci√≥n de Resultados"]
        E2 --> J[Resultados supervisados]
        H2 --> J
        H1 --> J
    end

    J --> K[Interpretaci√≥n final<br>Emoci√≥n + Temas emergentes]

    %% === Estilos ===
    style FeatureUnion fill:#FFE0B2,stroke:#EF6C00,stroke-width:2px
    style DictVect fill:#FFF3E0,stroke:#FB8C00,stroke-width:1.5px
    style Stacking fill:#BBDEFB,stroke:#1565C0,stroke-width:2px
    style Clustering fill:#F1F3F4,stroke:#9AA0A6,stroke-width:1px
    style Integracion fill:#E8F5E9,stroke:#2E7D32,stroke-width:2px

```


> Nota: UMAP y t-SNE son reducci√≥n de dimensionalidad, no clustering.

<h6>
<br>Elaborado con: <a href="https://mermaid.js.org/syntax/flowchart.html" target="_blank">Mermaid - Flowchart</a>
</h6>

<br>

> **Nota:** Aunque este proyecto se describe en espa√±ol, los datasets y modelos se entrenan con poemas en ingl√©s, debido a la mayor disponibilidad de recursos NLP en ese idioma.

<br>

üìò Ejemplo po√©tico: **Los Heraldos Negros**

> ‚ÄúHay golpes en la vida, tan fuertes... ¬°Yo no s√©!<br>
> Golpes como del odio de Dios; como si ante ellos,<br>
> la resaca de todo lo sufrido<br>
> se empozara en el alma... ¬°Yo no s√©!‚Äù

En la versi√≥n inglesa:

> ‚ÄúThere are blows in life, so powerful... I don't know!<br>
> Blows as from God's hatred; as if before them,<br>
> the backlash of everything suffered<br>
> were to dam up in the soul... I don't know!‚Äù<br>

<br>

## üóÇÔ∏è Dataset
El dataset combina poemas en dominio p√∫blico y textos etiquetados a partir de fuentes abiertas (HuggingFace / Kaggle).  

Cuando no hay etiquetas manuales, se aplican modelos de An√°lisis de Sentimientos (*sentiment analysis*) como punto de partida.

kaggle:
- [Poetry Foundation Poems](https://www.kaggle.com/datasets/tgdivy/poetry-foundation-poems/data)

Fundaci√≥n BBVA

- [C√©sar Vallejo - Poemas Humanos|Human Poems](https://fundacionbbva.pe/wp-content/uploads/2016/04/libro_000015.pdf)
  
- [C√©sar Vallejo - The Complete Posthumous Poetry](https://fundacionbbva.pe/wp-content/uploads/2016/04/libro_000015.pdf)

## üßÆ Representaci√≥n Vectorial de la Poes√≠a

Para analizar la poes√≠a desde una perspectiva computacional, los textos deben transformarse en representaciones num√©ricas.

Con ello se puede aplicar *embeddings* y algoritmos de *clustering* o *classification*.

Esta secci√≥n describe c√≥mo se generan las primeras representaciones usando enfoques cl√°sicos de **bag-of-words**: `CountVectorizer`, `TF-IDF Vectorizer` y `DictVectorizer`, antes de generar *embeddings* m√°s complejos.

---

### üîπ CountVectorizer

El **CountVectorizer** convierte cada poema en un vector basado en la frecuencia de aparici√≥n de cada t√©rmino.

Sea un corpus con $( D )$ documentos y un vocabulario con $( N )$ t√©rminos distintos.  
Para un documento $( d )$ y un t√©rmino $( t )$, el valor en la matriz $( X_{d,t} )$ es:

$$
X_{d,t} = \text{count}(t, d)
$$

donde

$$[
\text{count}(t, d) = \text{n√∫mero de veces que el t√©rmino } t \text{ aparece en el documento } d
]$$

Cada poema queda representado como un vector:

$$
\mathbf{x}_d = [X_{d,1}, X_{d,2}, ..., X_{d,N}]
$$

### ‚úçÔ∏è Ejemplo pr√°ctico ‚Äî *Los Heraldos Negros*

Consideremos el verso inicial de C√©sar Vallejo:

> ‚ÄúHay golpes en la vida, tan fuertes... ¬°Yo no s√©!‚Äù

#### üß© Limpieza del texto
Despu√©s de normalizar, eliminar signos y *stopwords*, el texto puede quedar as√≠:

```python
tokens = ["golpes", "vida", "tan", "fuertes"]
```

Dependiendo del idioma y la lista de stopwords usada, pueden quedar entre **3 y 6 t√©rminos relevantes**.
Ese n√∫mero es el que se utiliza como denominador en el c√°lculo de la frecuencia (TF).

#### üß© CountVectorizer
Si el vocabulario relevante es  (se considera `tan` como stopword)

```python
["golpes", "vida", "fuertes"]
```

entonces:

$$
\mathbf{x}_{\text{count}} = [1, 1, 1]
$$

Cada palabra aparece una vez.

---

### üîπ TF-IDF Vectorizer

El **TF-IDF (Term Frequency‚ÄìInverse Document Frequency)** pondera la frecuencia de los t√©rminos por su rareza en el conjunto de poemas.  
As√≠, las palabras comunes reciben menos peso y las m√°s singulares destacan en la representaci√≥n.

$$
\text{tfidf}(t, d, D) = \text{tf}(t, d) \times \text{idf}(t, D)
$$

donde

$$
\text{tf}(t, d) = \frac{f_{t,d}}{\sum_{t'} f_{t',d}}, \quad
\text{idf}(t, D) = \log\left(\frac{1 + |D|}{1 + |\{d_i \in D : t \in d_i\}|}\right) + 1
$$

Por tanto:

$$
\text{TFIDF}(t, d, D) = \frac{f_{t,d}}{\sum_{t'} f_{t',d}} \times \log\left(\frac{1 + |D|}{1 + |\{d_i \in D : t \in d_i\}|}\right) + 1
$$

---

#### üß© Ejemplo TF-IDF Vectorizer

Supongamos un corpus de tres versos de C√©sar Vallejo:

```python
from typing import Dict

verso: Dict[int: str] = {
    1: "Hay golpes en la vida, tan fuertes... ¬°Yo no s√©!"
    2: "Golpes como del odio de Dios;"
    3: "Son las ca√≠das hondas de los Cristos del alma."
}
```

Si el t√©rmino **"golpes"** aparece en 2 de 3 documentos, y **"vida"** solo en uno:

$$
\text{idf}(\text{golpes}) = \log\left(\frac{1 + 3}{1 + 2}\right) + 1 \approx 1.287
$$

$$
\text{idf}(\text{vida}) = \log\left(\frac{1 + 3}{1 + 1}\right) + 1 \approx 1.693
$$

Dado que cada palabra aparece una vez y el poema tiene 6 t√©rminos relevantes (seg√∫n el preprocesamiento elegido):

$$
\text{tf}(t, d) = \frac{1}{6}
$$

Entonces:

$$
\text{tfidf}(\text{golpes}) = \frac{1}{6} \times 1.287 \approx 0.215
$$

$$
\text{tfidf}(\text{vida}) = \frac{1}{6} \times 1.693 \approx 0.282
$$

$$
\text{tfidf}(\text{fuertes}) = \frac{1}{6} \times 1.693 \approx 0.282
$$

Por tanto, el vector TF-IDF ser√≠a:

$$
\mathbf{x}_{\text{tfidf}} = [0.215, 0.282, 0.282]
$$

---


### üîπ DictVectorizer

El DictVectorizer permite convertir diccionarios de frecuencias o caracter√≠sticas personalizadas en vectores num√©ricos.

Es √∫til cuando cada poema ya fue transformado en una estructura tipo diccionario, por ejemplo:


```python
from sklearn.feature_extraction import DictVectorizer
from typing import Dict

verso: Dict[str, int] = [
    {"golpes": 2, "vida": 1},
    {"odio": 1, "dios": 1, "golpes": 1}
]

vectorizer = DictVectorizer()
X = vectorizer.fit_transform(verso)
```

El resultado es una matriz dispersa con dimensiones iguales al vocabulario global.
Cada columna representa una palabra y cada fila un verso.

El `DictVectorizer` es particularmente √∫til si antes aplicas una limpieza o un conteo personalizado (por ejemplo, solo de sustantivos o adjetivos).

---

### üí° Interpretaci√≥n

- **CountVectorizer:** solo cuenta ocurrencias: √∫til para observar repeticiones l√©xicas.
- **TF-IDF Vectorizar:** valora la **relevancia sem√°ntica** de los t√©rminos √∫nicos o pocos frecuentes.
- **DictVectorizer:** traduce diccionarios personalizados en vectores, √∫til para features ling√º√≠sticas.

En poes√≠a, donde cada palabra tiene un peso emocional y simb√≥lico, **TF-IDF** refleja mejor la singularidad expresiva de cada poema, esas que, como en Vallejo, "duelen en el alma y pesan en la historia".

---


### üîπ Similitud del Coseno ‚Äî Distancia entre almas po√©ticas

Una vez que los poemas han sido transformados en vectores (por ejemplo, con TF-IDF Vectorizer), se puede medir qu√© tan cercos sem√°nticamente est√°n dos versos o poemas.

La medida m√°s utilizada para esto es la similitud del coseno:

$$
similitudCoseno(A, B) = 
\frac{A \cdot B}{\|A\| \, \|B\|} =
\frac{\sum_{i=1}^{n} A_i B_i}{\sqrt{\sum_{i=1}^{n} A_i^2} \, \sqrt{\sum_{i=1}^{n} B_i^2}}
$$

#### üß© Ejemplo Similitud del Coseno

Tomemos 2 versos de C√©sar Vallejo:

```python
from typing import Dict

verso: Dict[int: str] = {
    1: "Hay golpes en la vida, tan fuertes... ¬°Yo no s√©!"
    2: "Golpes como del odio de Dios;"
}
```

A partir del preprocesamiento y c√°lculo TF-IDF previo, se tiene:

$$
\mathbf{x}_{\text{v1}} = [0.215, 0.282, 0.282]
$$

Y para el segundo verso, aplicando el mismo procedimiento:

$$
\mathbf{x}_{\text{v2}} = [0.215, 0.215, 0.564]
$$

El vocabulario com√∫n es:

```python
["golpes", "vida", "dios"]
```

Siendo su representaci√≥n tridimensional de los dos versos de Los Heraldos Negros en el espacio de embeddings TF-IDF.
El vector azul claro -dodgerblue- corresponde al primer verso (‚ÄúHay golpes en la vida, tan fuertes... ¬°Yo no s√©!‚Äù) y el naranja al segundo (‚ÄúGolpes como del odio de Dios;‚Äù).

Esta visualizaci√≥n permite observar c√≥mo las diferencias en el peso sem√°ntico y frecuencia de t√©rminos alteran la direcci√≥n y magnitud de los vectores en el espacio.

<div style="text-align: center; padding: 5px;">
    <img src="./figs/vallejo_tfidf_vectors.png" />
</div>

### C√°lculo paso a paso

1. Producto punto:

$$
A \cdot B = (0.215)(0.215) + (0.282)(0.215) + (0.282)(0.564) = 0.252
$$


2. Norma de cada vector:

$$
\|A\| = \sqrt{0.215^2 + 0.282^2 + 0.282^2} = 0.464
$$

$$
\|B\| = \sqrt{0.215^2 + 0.215^2 + 0.564^2} = 0.641
$$

3. Similitud del coseno:

$$
similitudCoseno(A, B) = \frac{0.252}{0.464 \times 0.641} \approx 0.845
$$

---

###  üí° Interpretaci√≥n

- La similitud de **0.845** indica una **fuerte afinidad sem√°ntica** entre ambos versos: ambos giran en torno al concepto de golpe, vida y el dolor divino.

- En t√©rminos po√©ticos, se podr√≠a decir que ambos fragmentos **vibran en la misma frecuencia emocional**, aunque sus palabras difieran.

**‚ÄúAs√≠, el vector no mide rimas, sino resonancias del alma.‚Äù** üí´


### üîπ La apariencia ‚Äúorg√°nica‚Äù

<div style="text-align: center; padding: 5px;">
    <img src="./figs/poemas_2d_umap_clustering_kmeans.png" />
</div>

Las ramificaciones son poemas que comparten similitudes con varios grupos ‚Üí quedan como ‚Äúpuentes‚Äù o ‚Äúbrazos‚Äù.

Los nudos o concentraciones (zonas densas) son grupos de poemas con vocabulario/emoci√≥n muy parecida.

El hecho de que se vean como filamentos o bacterias es porque UMAP estira el espacio para mostrar continuidad entre regiones.

--- 

#### üí° Interpretaci√≥n pr√°ctica

Si en el corpus hay poemas con temas/emociones muy conectados (por ejemplo, dolor ‚Üî muerte ‚Üî desesperanza en Vallejo), UMAP los hilvana en curvas continuas.

Si fueran m√°s disjuntos (ej. poemas amorosos vs poemas pol√≠ticos), ver√≠as islas separadas, no ramificaciones.

En poes√≠a esto es natural: los temas no son r√≠gidos, sino que fluyen de uno a otro. El gr√°fico refleja precisamente esa transici√≥n sem√°ntica difusa.

## üìì Notebooks

Algunos notebooks incluyen diagramas interactivos (por ejemplo, pipelines de scikit-learn).
GitHub no los renderiza correctamente.

Para una visualizaci√≥n completa, se recomienda usar **nbviewer**:

- [02_feature_pipeline.ipynb (nbviewer)](https://nbviewer.org/github/HubertRonald/VersoVector/blob/main/notebook/02_feature_pipeline.ipynb)
- [03_embeddings_supervised.ipynb (nbviewer)](https://nbviewer.org/github/HubertRonald/VersoVector/blob/main/notebook/03_embeddings_supervised.ipynb)
- [04_embeddings_unsupervised.ipynb (nbviewer)](https://nbviewer.org/github/HubertRonald/VersoVector/blob/main/notebook/04_embeddings_unsupervised.ipynb)

## .gitignore

Fue generado en [gitignore.io](https://www.toptal.com/developers/gitignore/) con los filtros `python`, `macos`, `windows` y consumido mediante su API como archivo crudo desde la terminal:

```bash
curl -L https://www.toptal.com/developers/gitignore/api/python,macos,windows > .gitignore
```

## ü™∂ Autores

- **Hubert Ronald** - *Trabajo Inicial* - [HubertRonald](https://github.com/HubertRonald)

- Ve tambi√©n la lista de [contribuyentes](https://github.com/HubertRonald/VersoVector/contributors) que participaron en este proyecto.


## üìö Licencia y derechos de autor

El c√≥digo fuente de este proyecto se distribuye bajo licencia MIT - ver la [LICENCIA](LICENSE) archivo (en ingl√©s) para m√°s detalle.

Los textos po√©ticos utilizados (como los de C√©sar Vallejo) provienen de **fuentes de dominio p√∫blico o traducciones disponibles con fines educativos**.

En caso de utilizar materiales con derechos reservados, estos se emplean √∫nicamente para fines de **investigaci√≥n, an√°lisis ling√º√≠stico y demostraci√≥n acad√©mica**, sin fines comerciales.